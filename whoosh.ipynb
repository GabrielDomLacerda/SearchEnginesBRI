{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, ID, TEXT\n",
    "from whoosh.analysis import StandardAnalyzer\n",
    "from whoosh import index\n",
    "from whoosh.index import create_in\n",
    "from whoosh.qparser import MultifieldParser, OrGroup, FuzzyTermPlugin, QueryParser\n",
    "import os.path\n",
    "import re\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(index=ID(stored=True),\n",
    "                title=TEXT(stored=True),\n",
    "                author=TEXT(stored=True),\n",
    "                bibliography=TEXT(stored=True),\n",
    "                body=TEXT(analyzer=StandardAnalyzer(stoplist=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIRECTORY = \"index_dir\"\n",
    "if not os.path.exists(INDEX_DIRECTORY):\n",
    "    os.mkdir(INDEX_DIRECTORY)\n",
    "ix = create_in(INDEX_DIRECTORY, schema)\n",
    "ix = index.open_dir(INDEX_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text:\n",
    "\n",
    "    def __init__(self, original):\n",
    "        result = re.split(r'.T|.A|.B|.W', original.replace('\\n', ' '))\n",
    "        self.index, self.title, self.author, self.bibliography, self.body, *_ = result\n",
    "\n",
    "class Query:\n",
    "\n",
    "    def __init__(self, text):\n",
    "        result = text.split('\\n.W\\n')\n",
    "        self.index, self.body = map(lambda x: x.strip().replace('\\n', ' '),\n",
    "                                    result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_queries(filename):\n",
    "    queries = []\n",
    "    with open(filename, 'r') as file:\n",
    "        txt = file.read()\n",
    "        txt = txt.split('.I')[1:]\n",
    "        queries = list(map(lambda x: Query(x), txt))\n",
    "    return queries\n",
    "\n",
    "\n",
    "def parse_text(filename):\n",
    "    words = []\n",
    "    with open(filename, 'r') as file:\n",
    "        txt = file.read()\n",
    "        txt = txt.split('.I')[1:]\n",
    "        words = list(map(lambda x: Text(x), txt))\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_ordered_relevant_searches(filename):\n",
    "    query_relations = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        txt = file.read()\n",
    "        txt = txt.strip().split('\\n')\n",
    "        for i in txt:\n",
    "            query, abstract, score = map(\n",
    "                lambda x: int(x),\n",
    "                filter(lambda x: len(x) > 0,\n",
    "                       i.strip().split(' ')))\n",
    "            if query - 1 not in query_relations:\n",
    "                query_relations[query - 1] = [(abstract, score)]\n",
    "            else:\n",
    "                query_relations[query - 1].append((abstract, score))\n",
    "\n",
    "    #ordenando as relations por rank\n",
    "    for i in query_relations:\n",
    "        query_relations[i].sort(key=lambda x: x[1])\n",
    "\n",
    "    return query_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(parser, queries: list[Query], limits: list[int]):\n",
    "    results_dict = {}\n",
    "    with ix.searcher() as searcher:\n",
    "        for i, (limit, query_to_parse) in enumerate(zip(limits, queries)):\n",
    "            query = parser.parse(query_to_parse.body)\n",
    "            results = searcher.search(query, limit=max(limit, 10))\n",
    "            results_dict[i] = list(\n",
    "                map(lambda x: (int(x.get('index')), x.score), results))\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(search, relevant, k=None):\n",
    "    if k is None or k > len(search) or k > len(relevant):\n",
    "        k = min(len(search), len(relevant))\n",
    "\n",
    "    search = search[:k]\n",
    "    relevant = relevant[:k]\n",
    "\n",
    "    search_indexes = set(map(lambda x: x[0], search))\n",
    "    relevant_indexes = set(map(lambda x: x[0], relevant))\n",
    "\n",
    "    den = len(relevant_indexes)\n",
    "    num = len(relevant_indexes.intersection(search_indexes))\n",
    "\n",
    "    if den != 0:\n",
    "        return num / den\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def recall_at_k(search, relevant, k=None):\n",
    "    if k is None or k > len(search) or k > len(relevant):\n",
    "        k = min(len(search), len(relevant))\n",
    "\n",
    "    search = search[:k]\n",
    "    relevant = relevant[:k]\n",
    "\n",
    "    search_indexes = set(map(lambda x: x[0], search))\n",
    "    relevant_indexes = set(map(lambda x: x[0], relevant))\n",
    "\n",
    "    den = len(relevant)\n",
    "    num = len(relevant_indexes.intersection(search_indexes))\n",
    "\n",
    "    if den != 0:\n",
    "        return num / den\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_results_by_func(search_results_dict,\n",
    "                        revelant_results_dict,\n",
    "                        func,\n",
    "                        k=None):\n",
    "    results = list(\n",
    "        map(\n",
    "            lambda x: func(search_results_dict[x], revelant_results_dict[x], k\n",
    "                           ), range(len(revelant_results_dict))))\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_results(search_results_dict,\n",
    "                 revelant_results_dict,\n",
    "                 func,\n",
    "                 title: str = '',\n",
    "                 k_s=[1, 5, 10, None]):\n",
    "    fig, axis = plt.subplots(len(k_s))\n",
    "    fig.suptitle(title)\n",
    "    for i, k in enumerate(k_s):\n",
    "        r = all_results_by_func(search_results_dict,\n",
    "                                revelant_results_dict,\n",
    "                                func,\n",
    "                                k=k)\n",
    "        axis[i].plot(range(len(r)), r)\n",
    "        k_name = f'{k}' if k is not None else 'MAX'\n",
    "        axis[i].set_title(f'{func.__name__}={k_name}')\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBTENDO PALAVRAS\n",
    "queries = parse_queries('cran/cran.qry')\n",
    "\n",
    "#OBTENDO QUERIES\n",
    "words = parse_text('cran/cran.all.1400')\n",
    "\n",
    "#OBTENDO BUSCAS RELEVANTES\n",
    "query_relations = get_ordered_relevant_searches('cran/cranqrel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDEXANDO RESULTADOS\n",
    "t0 = timeit.default_timer()\n",
    "writer = ix.writer()\n",
    "error = False\n",
    "\n",
    "for word in words:\n",
    "    try:\n",
    "        writer.add_document(index=f'{word.index}',\n",
    "                            title=word.title,\n",
    "                            author=word.author,\n",
    "                            bibliography=word.bibliography,\n",
    "                            body=word.body)\n",
    "    except ValueError:\n",
    "        error = True\n",
    "        break\n",
    "\n",
    "if error:\n",
    "    writer.cancel()\n",
    "else:\n",
    "    writer.commit()\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(f'TEMPO DE INDEXAÇÃO {(t1 - t0):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = list(map(lambda x: len(x), query_relations.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = MultifieldParser(fieldnames=[\"title\", \"author\", \"body\"],\n",
    "                          schema=schema,\n",
    "                          group=OrGroup)\n",
    "parser.add_plugin(FuzzyTermPlugin())\n",
    "\n",
    "#BUSCA 1: TITULO, AUTOR E CORPO\n",
    "t0 = timeit.default_timer()\n",
    "results_dict = search_results(parser, queries, limits)\n",
    "t1 = timeit.default_timer()\n",
    "print(f'TEMPO DA BUSCA 1 {(t1 - t0):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_s = [1, 5, 10, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO TODAS AS PRECISIONS PARA BUSCA 1\n",
    "plot_results(results_dict, query_relations, precision_at_k,\n",
    "             'Cálculo das precisions para busca 1', k_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO TODAS OS RECALLS PARA BUSCA 1\n",
    "plot_results(results_dict, query_relations, recall_at_k,\n",
    "             'Cálculo dos recalls para busca 1', k_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_query = QueryParser(\"body\", schema=schema, group=OrGroup)\n",
    "parser_query.add_plugin(FuzzyTermPlugin())\n",
    "\n",
    "#BUSCA 2: SOMENTE CORPO\n",
    "t0 = timeit.default_timer()\n",
    "results_dict_qp = search_results(parser_query, queries, limits)\n",
    "t1 = timeit.default_timer()\n",
    "print(f'TEMPO DA BUSCA 2 {(t1 - t0):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO TODAS AS PRECISIONS PARA BUSCA 2\n",
    "plot_results(results_dict_qp, query_relations, precision_at_k,\n",
    "             'Cálculo das precisions para busca 2', k_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO TODAS OS RECALLS PARA BUSCA 2\n",
    "plot_results(results_dict_qp, query_relations, recall_at_k,\n",
    "             'Cálculo dos recalls para busca 2', k_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
